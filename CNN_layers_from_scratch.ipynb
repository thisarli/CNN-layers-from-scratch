{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thisarli/CNN-layers-from-scratch/blob/main/CNN_layers_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Installs"
      ],
      "metadata": {
        "id": "xhx1IQbdtBS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxh3EiNq7mSn",
        "outputId": "9735bfc6-2afd-433b-968b-8440f39d9ba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch torchvision sklearn seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "53jMRaMRuW4_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OplG2ZNZuW5S"
      },
      "source": [
        "# 2D convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b2FymI-duW5W"
      },
      "outputs": [],
      "source": [
        "class Conv2d(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 padding=0,\n",
        "                 bias=True):\n",
        "\n",
        "        super(Conv2d, self).__init__()\n",
        "        \"\"\"\n",
        "        2D convolution layer, with variable padding and stride.\n",
        "        \"\"\"\n",
        "\n",
        "        if type(kernel_size) is int:\n",
        "          self.kernel_x = kernel_size\n",
        "          self.kernel_y = kernel_size\n",
        "        elif type(kernel_size) is tuple:\n",
        "          self.kernel_x = kernel_size[0]\n",
        "          self.kernel_y = kernel_size[-1]\n",
        "\n",
        "        if type(stride) is int:\n",
        "          self.stride_x = stride\n",
        "          self.stride_y = stride\n",
        "        elif type(stride) is tuple:\n",
        "          self.stride_x = stride[0]\n",
        "          self.stride_y = stride[-1]\n",
        "\n",
        "        if type(padding) is int:\n",
        "          self.padding_x = padding\n",
        "          self.padding_y = padding\n",
        "        elif type(padding) is tuple:\n",
        "          self.padding_x = padding[0]\n",
        "          self.padding_y = padding[-1]\n",
        "        \n",
        "        # Weights shape: [out_channels, in_channels, kernel_x, kernel_y]\n",
        "        self.w = torch.nn.Parameter(torch.randn(size=(out_channels, in_channels, self.kernel_x, self.kernel_y)))\n",
        "        # Bias shape: [out_channels] \n",
        "        self.b = torch.nn.Parameter(torch.zeros(size=(out_channels,)))\n",
        "        self.F = out_channels\n",
        "        self.C = in_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.bias = bias\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Feed-forward function\n",
        "\n",
        "        Input shape: [N, C, H, W]\n",
        "        Output shape: [N, F, H', W']\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        input_channels = x.shape[1]\n",
        "        input_height = x.shape[2]\n",
        "        input_width = x.shape[3]\n",
        "\n",
        "        output_height = int((input_height + 2 * self.padding_y - self.kernel_y) / self.stride_y + 1)\n",
        "        output_width = int((input_width + 2 * self.padding_x - self.kernel_x) / self.stride_x + 1)\n",
        "\n",
        "        # Retrieve x_unfolded (unfolded input)\n",
        "        x_unfolded = F.unfold(x, kernel_size=self.kernel_size, padding=self.padding, stride=self.stride)\n",
        "        # Retrieve output_unfolded via matrix multiplication with parameters of filter\n",
        "        output_unfolded = x_unfolded.transpose(1, 2).matmul(self.w.view(self.w.size(0), -1).t())\n",
        "        # Add bias if true\n",
        "        if self.bias is True:\n",
        "          output_unfolded = output_unfolded.add(self.b)\n",
        "        # Fold output into correct format\n",
        "        out = F.fold(output_unfolded.transpose(1, 2), (output_width, output_height), (1, 1))\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D max pooling"
      ],
      "metadata": {
        "id": "j6uDJSkWtLMn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ThrRIjf9uW5a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MaxPool2d(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super(MaxPool2d, self).__init__()\n",
        "        \"\"\"\n",
        "        Max-pooling layer with variable kernel size to take max over\n",
        "        \"\"\"\n",
        "        self.stride = kernel_size\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "        if type(kernel_size) is int:\n",
        "          self.kernel_x = kernel_size\n",
        "          self.kernel_y = kernel_size\n",
        "          self.stride_x = kernel_size\n",
        "          self.stride_y = kernel_size\n",
        "        elif type(kernel_size) is tuple:\n",
        "          self.kernel_x = kernel_size[0]\n",
        "          self.kernel_y = kernel_size[-1]\n",
        "          self.stride_x = kernel_size[0]\n",
        "          self.stride_y = kernel_size[-1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Feed-forward function\n",
        "\n",
        "        Input shape: [N, C, H, W]\n",
        "        Output shape: [N, F, H', W']\n",
        "        \"\"\"\n",
        "        x_unfolded = x.unfold(2, self.kernel_x, self.stride_x).unfold(3, self.kernel_y, self.stride_y)\n",
        "        x_unfolded = x_unfolded.contiguous().view(*x_unfolded.size()[:-2], -1)\n",
        "        # Apply max\n",
        "        out, _ = x_unfolded.max(4)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear layer"
      ],
      "metadata": {
        "id": "Wq5cr-2ZtOpi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t4jqNUbguW5d"
      },
      "outputs": [],
      "source": [
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bias=True):\n",
        "        super(Linear, self).__init__()\n",
        "        \"\"\"\n",
        "        Linear layer.\n",
        "        \"\"\"\n",
        "        self.w = torch.nn.Parameter(torch.randn(size=(in_channels, out_channels)))  # shape [in_channels, out_channels]\n",
        "        self.b = torch.nn.Parameter(torch.randn(size=(out_channels,)))  # shape [out_channels]\n",
        "        self.bias = bias\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Feed-forward function\n",
        "        \"\"\"\n",
        "        if self.bias is True:\n",
        "          out = x.matmul(self.w) + self.b\n",
        "\n",
        "        else:\n",
        "          out = x.matmul(self.w)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D batch normalization"
      ],
      "metadata": {
        "id": "hhSDIMswtR_R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "je2rfaENuW5f"
      },
      "outputs": [],
      "source": [
        "class BatchNorm2d(nn.Module):\n",
        "    def __init__(self, num_features, eps=1e-05, momentum=0.1):\n",
        "        super(BatchNorm2d, self).__init__()\n",
        "        \"\"\"\n",
        "        Batch Normalization for 2D image mini-batch.\n",
        "        \"\"\"\n",
        "        self.num_features = num_features\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.ones(size=(1, num_features, 1, 1)))\n",
        "        self.beta = nn.Parameter(torch.zeros(size=(1, num_features, 1, 1)))\n",
        "\n",
        "        self.moving_mean = torch.zeros(size=(1, num_features, 1, 1))\n",
        "        self.moving_var = torch.ones(size=(1, num_features, 1, 1))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Feed-forward function\n",
        "\n",
        "        Input shape: [N, C, H, W]\n",
        "        Output shape: [N, C, H, W] (same shape as input)\n",
        "        \"\"\"\n",
        "        #if not torch.is_grad_enabled():\n",
        "        if self.training is False:\n",
        "          # Generate normalised input\n",
        "          x_norm = (x - self.moving_mean) / torch.sqrt(self.moving_var + self.eps)\n",
        "\n",
        "        # Otherwise training (where we need access to the gradients)\n",
        "        else:\n",
        "          # Calculate mean from mini batch\n",
        "          mean = x.mean(dim=(0, 2, 3), keepdim=True)\n",
        "          # Calculate biased variance from minibatch\n",
        "          var = ((x - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
        "          # Normalise\n",
        "          x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "          # Update moving average and variance during training\n",
        "          self.moving_mean = self.momentum * mean + (1.0 - self.momentum) * self.moving_mean\n",
        "          self.moving_var = self.momentum * var + (1.0 - self.momentum) * self.moving_var\n",
        "\n",
        "        # Scaling via gamma / shifting via beta\n",
        "        x = self.gamma * x_norm + self.beta\n",
        "\n",
        "        return x"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "otter": {
      "tests": {
        "BatchNorm Layer": {
          "name": "BatchNorm Layer",
          "points": 15,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> list(BatchNorm2d(2)(torch.zeros((3,2,7,6))).shape) == [3,2,7,6]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> type(BatchNorm2d(2)(torch.zeros((3,2,7,6)))) == torch.Tensor\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> hasattr(BatchNorm2d(2), 'gamma') and hasattr(BatchNorm2d(2), 'beta')\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> layer = BatchNorm2d(7)\n>>> (list(layer.gamma.shape) == [7])  and (list(layer.beta.shape) == [7])\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Convolution Layer": {
          "name": "Convolution Layer",
          "points": 15,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> list(Conv2d(3,7,9)(torch.zeros((10, 3,64,64))).shape) == [10,7,56,56]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> type(Conv2d(1,3,2)(torch.zeros((7,1,32,32)))) in [torch.Tensor, torch.nn.Parameter]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> hasattr(Conv2d(1,1,1), 'w') and hasattr(Conv2d(1,1,1), 'b')\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> layer = Conv2d(7,32,4)\n>>> (list(layer.w.shape) == [32,7,4,4])  and (list(layer.b.shape) == [32])\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "Linear Layer": {
          "name": "Linear Layer",
          "points": 5,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> list(Linear(25,28)(torch.zeros((17,25))).shape) == [17,28]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> type(Linear(13,15)(torch.zeros((6,13)))) in [torch.Tensor, torch.nn.Parameter]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> hasattr(Linear(2,2), 'w') and hasattr(Linear(2,2), 'b')\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> layer = Linear(13,24)\n>>> (list(layer.w.shape) in [[13,24], [24,13]])  and (list(layer.b.shape) == [24])\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "MaxPool Layer": {
          "name": "MaxPool Layer",
          "points": 15,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> list(MaxPool2d(3)(torch.zeros((10,3,64,64))).shape) == [10,3,21,21]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                },
                {
                  "code": ">>> type(MaxPool2d(3)(torch.zeros((10,3,64,64)))) in [torch.Tensor]\nTrue",
                  "hidden": false,
                  "locked": false,
                  "points": 0
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}